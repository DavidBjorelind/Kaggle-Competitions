{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation & Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "5      0            330877   8.4583   NaN        Q  \n",
      "6      0             17463  51.8625   E46        S  \n",
      "7      1            349909  21.0750   NaN        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>AgeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age     Fare  Embarked  FamilySize  IsAlone  AgeClass\n",
       "0       3    1  22.0   7.2500       1.0           2        0      66.0\n",
       "1       1    2  38.0  71.2833       2.0           2        0      38.0\n",
       "2       3    2  26.0   7.9250       1.0           1        1      78.0\n",
       "3       1    2  35.0  53.1000       1.0           2        0      35.0\n",
       "4       3    1  35.0   8.0500       1.0           1        1     105.0\n",
       "5       3    1  28.0   8.4583       3.0           1        1      84.0\n",
       "6       1    1  54.0  51.8625       1.0           1        1      54.0\n",
       "7       3    1   2.0  21.0750       1.0           5        0       6.0\n",
       "8       3    2  27.0  11.1333       1.0           3        0      81.0\n",
       "9       2    2  14.0  30.0708       2.0           2        0      28.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "feat = train_data.columns\n",
    "\n",
    "print(train_data.head(10))\n",
    "#mapping = {'S':1, 'C':2, 'Q':3}\n",
    "#test_data['Embarked'] = [mapping[i] for i in test_data['Embarked']]\n",
    "#train_data['Embarked'] = [mapping[i] for i in train_data['Embarked']]\n",
    "test_data.replace(to_replace=['S', 'C', 'Q'], value=[1,2,3], inplace=True)\n",
    "train_data.replace(to_replace=['S', 'C', 'Q'], value=[1,2,3], inplace=True)\n",
    "\n",
    "test_data.replace(to_replace=['male', 'female'], value=[1,2], inplace=True)\n",
    "train_data.replace(to_replace=['male', 'female'], value=[1,2], inplace=True)\n",
    "\n",
    "# Dropping NaNs and replacing with median\n",
    "test_data['Age'].fillna(test_data['Age'].dropna().median(), inplace=True)\n",
    "train_data['Age'].fillna(train_data['Age'].dropna().median(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].dropna().median(), inplace=True)\n",
    "train_data['Fare'].fillna(train_data['Fare'].dropna().median(), inplace=True)\n",
    "test_data.fillna(0, inplace=True)\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "# Adding FamilySize\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "\n",
    "# Adding IsAlone\n",
    "test_data['IsAlone'] = 0\n",
    "test_data.loc[test_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "train_data['IsAlone'] = 0\n",
    "train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Adding AgeClass\n",
    "test_data['AgeClass'] = test_data['Age'] * test_data['Pclass']\n",
    "train_data['AgeClass'] = train_data['Age'] * train_data['Pclass']\n",
    "\n",
    "\n",
    "# Extracting desired features from array \n",
    "used_feats = ['Pclass', 'Sex', 'Age', 'Fare',\n",
    "              'Embarked', 'FamilySize', 'IsAlone', 'AgeClass']\n",
    "# 'Ticket', 'Cabin', 'SibSp', 'Parch'\n",
    "train_x = train_data[used_feats]\n",
    "test_x  = test_data[used_feats]\n",
    "train_y = train_data['Survived']\n",
    "test_id = test_data['PassengerId']\n",
    "\n",
    "# The final features used\n",
    "train_x.head(10)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.020000000000000004, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Picking the best parameters\n",
    "\n",
    "params = {'kernel': ('linear', 'rbf', 'poly'), 'C': np.linspace(0.01,0.1, 10)}\n",
    "\n",
    "model = svm.SVC()\n",
    "cf = GridSearchCV(model, params, cv=5, n_jobs=-1)\n",
    "cf.fit(train_x, train_y)\n",
    "cf.best_params_\n",
    "\n",
    "\n",
    "\n",
    "#model = svm.SVC(kernel='rbf', gamma=1, C=1000)\n",
    "#model.fit(train_x, train_y)\n",
    "#pred = model.predict(test_x)\n",
    "#acc = round(model.score(train_x, train_y) * 100, 2)\n",
    "#print(acc) # 0.976\n",
    "# Cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.46\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear', C=0.0242)\n",
    "model.fit(train_x, train_y)\n",
    "pred = model.predict(test_x)\n",
    "acc = round(model.score(train_x, train_y) * 100, 2) # Don't know what this does...\n",
    "print(acc) # 0.976"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({\n",
    "    'PassengerId': test_id,\n",
    "    'Survived': pred\n",
    "})\n",
    "\n",
    "# Saving as csv\n",
    "preds = df_pred.to_csv('dbjrelind2_pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/soham1024/titanic-data-science-eda-with-meme-solution/comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
